<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <link rel="stylesheet" href="css/example.css">
    <script src="utils/gl-matrix.js"></script>
</head>
<!--
  The MIT License (MIT)

  Copyright (c) 2024 Tarek Sherif

  Permission is hereby granted, free of charge, to any person obtaining a copy of
  this software and associated documentation files (the "Software"), to deal in
  the Software without restriction, including without limitation the rights to
  use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
  the Software, and to permit persons to whom the Software is furnished to do so,
  subject to the following conditions:

  The above copyright notice and this permission notice shall be included in all
  copies or substantial portions of the Software.

  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
  FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
  COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
  IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
  CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
-->
<body>
<canvas id="webgpu-canvas"></canvas>
<script type="module">
import { checkSupport, addDescription, loadImageBitmaps, createCube, createSphere, createQuad, xformMatrix, randomRange } from "./utils/utils.js";
const { mat4, vec3 } = glMatrix;

const NUM_BOXES = 256;
const NUM_LIGHTS = 512;

checkSupport();
addDescription(
    "Deferred Rendering",
    `Rendering ${NUM_BOXES} boxes to a gBuffer and animating ${NUM_LIGHTS} lights.`,
    "deferred.html"
);

(async () => {
    //////////////////////////////////////////
    // Set up WebGPU adapter
    //////////////////////////////////////////

    const [adapter, [image]] = await Promise.all([
        navigator.gpu.requestAdapter(),
        loadImageBitmaps(["img/webgpu.png"])
    ]);

    const presentationFormat = navigator.gpu.getPreferredCanvasFormat();

    ////////////////////////////////////
    // Set up device and canvas context
    ////////////////////////////////////

    const device = await adapter.requestDevice({
        requiredLimits: {
            maxColorAttachmentBytesPerSample: 40
        },
        requiredFeatures: ["float32-filterable"]
    });
    
    const canvas = document.getElementById("webgpu-canvas");
    canvas.width = window.innerWidth;
    canvas.height = window.innerHeight;

    const context = canvas.getContext("webgpu");
    context.configure({
        device,
        format: presentationFormat
    });

    const msaaTexture = device.createTexture({
        label: 'msaa texture',
        size: [canvas.width, canvas.height],
        format: presentationFormat,
        usage: GPUTextureUsage.RENDER_ATTACHMENT,
        sampleCount: 4
    });

    ////////////////////////////////////////
    // Create vertex buffers and load data
    ////////////////////////////////////////

    const cubeData = createCube();

    const cube = {
        positions: device.createBuffer({
            size: cubeData.positions.byteLength,
            usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST
        }),
        normals: device.createBuffer({
            size: cubeData.normals.byteLength,
            usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST
        }),
        uvs: device.createBuffer({
            size: cubeData.uvs.byteLength,
            usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST
        }),
        count: cubeData.positions.length / 3
    };
    

    device.queue.writeBuffer(cube.positions, 0, cubeData.positions);
    device.queue.writeBuffer(cube.normals, 0, cubeData.normals);
    device.queue.writeBuffer(cube.uvs, 0, cubeData.uvs);

    const sphereData = createSphere({
        latBands: 8,
        longBands: 8
    });

    const sphere = {
        positions: device.createBuffer({
            size: sphereData.positions.byteLength,
            usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST
        }),
        indices: device.createBuffer({
            size: sphereData.indices.byteLength,
            usage: GPUBufferUsage.INDEX | GPUBufferUsage.COPY_DST
        }),
        count: sphereData.indices.length
    };
    

    device.queue.writeBuffer(sphere.positions, 0, sphereData.positions);
    device.queue.writeBuffer(sphere.indices, 0, sphereData.indices);

    const quadData = createQuad();

    const quad = {
        positions: device.createBuffer({
            size: quadData.positions.byteLength,
            usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST
        }),
        count: quadData.positions.length / 2
    };
    

    device.queue.writeBuffer(quad.positions, 0, quadData.positions);

    /////////////////////////////////////////
    // Create texture, sampler and load data
    //////////////////////////////////////////

    const sampler = device.createSampler({
        minFilter: "linear",
        magFilter: "linear"
    });

    const colorTexture = device.createTexture({
        size: [image.width, image.height],
        format: "rgba8unorm",
        usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST | GPUTextureUsage.RENDER_ATTACHMENT
    });

    device.queue.copyExternalImageToTexture(
        { source: image, flipY: true },
        { texture: colorTexture },
        {
            width: image.width,
            height: image.height
        }
    );

    ///////////////////////
    // Uniform values
    ////////////////////////

    const projMatrix = mat4.create();
    mat4.perspectiveZO(projMatrix, Math.PI / 2, canvas.width / canvas.height, 0.1, 10.0);

    const viewMatrix = mat4.create();
    const eyePosition = vec3.fromValues(0, 0, 1);
    mat4.lookAt(viewMatrix, eyePosition, vec3.fromValues(0, 0, 0), vec3.fromValues(0, 1, 0));

    const viewProjectionMatrix = mat4.create();
    mat4.multiply(viewProjectionMatrix, projMatrix, viewMatrix);

    // Uniform buffer for view projection matrix
    // used in lights and gBuffer passes
    const viewProjectionMatrixBuffer = device.createBuffer({
        size: 64,
        usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });

    device.queue.writeBuffer(viewProjectionMatrixBuffer, 0, viewProjectionMatrix);


    ///////////////////////////////
    // Lights pass
    // (Render lights as spheres)
    ///////////////////////////////

    // Shader module
    const lightsShaderModule = device.createShaderModule({
        label: 'lights shader',
        code: `

            struct VSOut {
                @builtin(position) clipPosition: vec4f,
                @location(0) color: vec3f
            };

            @group(0) @binding(0) var<uniform> viewProjectionMatrix: mat4x4f;

            @vertex
            fn vs(
                @location(0) vertexPosition: vec3f,
                @location(1) position: vec3f,
                @location(2) color: vec3f,
            ) -> VSOut {
                let worldPosition: vec4f = vec4f(vertexPosition * 0.02 + position, 1.0);

                var vsOut: VSOut;
                vsOut.clipPosition = viewProjectionMatrix * worldPosition;
                vsOut.color = color.rgb;

                return vsOut;
            }

            @fragment
            fn fs(fsIn: VSOut) -> @location(0) vec4f {
                let maxChannel: f32 = max(fsIn.color.r, max(fsIn.color.g, fsIn.color.b));
                return vec4f(fsIn.color * (1.0 / maxChannel), 1.0);
            }

        `
    });

    // Pipeline
    const lightsPipeline = device.createRenderPipeline({
        label: 'lights pipeline',
        layout: 'auto',
        vertex: {
            module: lightsShaderModule,
            entryPoint: "vs",
            buffers: [
                {
                    arrayStride: 12,
                    attributes: [{
                        shaderLocation: 0,
                        format: "float32x3",
                        offset: 0
                    }]
                },
                {
                    arrayStride: 16,
                    stepMode: "instance",
                    attributes: [{
                        shaderLocation: 1,
                        format: "float32x3",
                        offset: 0
                    }]
                },
                {
                    arrayStride: 16,
                    stepMode: "instance",
                    attributes: [{
                        shaderLocation: 2,
                        format: "float32x3",
                        offset: 0
                    }]
                }
            ]
        },
        fragment: {
            module: lightsShaderModule,
            entryPoint: "fs",

            targets: [
                {
                    format: presentationFormat
                }
            ]
        },
        multisample: {
            count: 4
        },
        primitive: {
            topology: "triangle-list",
            cullMode: "back"
        },
        depthStencil: {
            format: "depth24plus",
            depthWriteEnabled: true,
            depthCompare: "less"
        }
    });

    // Objects
    // Buffers used as vertex data in the lights pass,
    // uniform data in the lighting pass.
    const lights = {
        data: new Array(NUM_LIGHTS).fill(null).map(() => ({
            position: [
                randomRange(-4, 4),
                randomRange(-4, 4),
                randomRange(-4, 1)
            ],
            color: [
                randomRange(0, 1),
                randomRange(0, 1),
                randomRange(0, 1)
            ],
            offset: [
                randomRange(-1, 1),
                randomRange(-1, 1),
                randomRange(-1, 1)
            ],
            t: randomRange(0, 2 * Math.PI),
        })),
        positionData: new Float32Array(NUM_LIGHTS * 4),
        positions: device.createBuffer({
            size: NUM_LIGHTS * 4 * Float32Array.BYTES_PER_ELEMENT,
            usage: GPUBufferUsage.VERTEX | GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
        }),
        colorData: new Float32Array(NUM_LIGHTS * 4),
        colors: device.createBuffer({
            size: NUM_LIGHTS * 4 * Float32Array.BYTES_PER_ELEMENT,
            usage: GPUBufferUsage.VERTEX | GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
        }),
        bindGroup: device.createBindGroup({
            layout: lightsPipeline.getBindGroupLayout(0),
            entries: [
                {
                    binding: 0,
                    resource: {
                        buffer: viewProjectionMatrixBuffer
                    }
                }
            ]
        })
    };
    
    lights.data.forEach((data, i) => {
        const index = i * 4;
        lights.positionData.set(data.position, index);
        lights.colorData.set(data.color, index);
    });

    device.queue.writeBuffer(lights.positions, 0, lights.positionData);
    device.queue.writeBuffer(lights.colors, 0, lights.colorData);

    ////////////////////////////
    // GBuffer pass
    // (Draw boxes to gBuffer)
    ////////////////////////////

    // Render targets
    const gBufferPositionsTexture = device.createTexture({
        size: [canvas.width, canvas.height],
        format: "rgba16float",
        usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.RENDER_ATTACHMENT,
        sampleCount: 4
    });

    const gBufferNormalsTexture = device.createTexture({
        size: [canvas.width, canvas.height],
        format: "rgba16float",
        usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.RENDER_ATTACHMENT,
        sampleCount: 4
    });

    const gBufferUVTexture = device.createTexture({
        size: [canvas.width, canvas.height],
        format: "rg16float",
        usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.RENDER_ATTACHMENT,
        sampleCount: 4
    });    

    // Shader module
    const gBufferShaderModule = device.createShaderModule({
        label: 'gbuffer shader',
        code: `
            struct VSOut {
                @builtin(position) clipPosition: vec4f,
                @location(0) worldPosition: vec3f,
                @location(1) normal: vec3f,
                @location(2) uv: vec2f,
            };

            @group(0) @binding(0) var<uniform> viewProjectionMatrix: mat4x4f;
            @group(0) @binding(1) var<uniform> worldMatrix: mat4x4f;

            @vertex
            fn vs(
                @location(0) position: vec4f,
                @location(1) normal: vec3f,
                @location(2) uv: vec2f,
            ) -> VSOut {
                let worldPosition: vec4f = worldMatrix * position;

                var vsOut: VSOut;
                vsOut.clipPosition = viewProjectionMatrix * worldPosition;
                vsOut.worldPosition = worldPosition.xyz;
                vsOut.normal = (worldMatrix * vec4f(normal, 0.0)).xyz;
                vsOut.uv = uv;

                return vsOut;
            }

            struct FSOut {
                @location(0) position: vec4f,
                @location(1) normal: vec4f,
                @location(2) uv: vec2f,
            }

            @fragment
            fn fs(fsIn: VSOut) -> FSOut {
                var fsOut: FSOut;
                fsOut.position = vec4f(fsIn.worldPosition, 1.0);
                fsOut.normal = vec4f(fsIn.normal, 0.0);
                fsOut.uv = fsIn.uv;

                return fsOut;
            }

        `
    });

    // Pipeline 
    const gBufferPipeline = device.createRenderPipeline({
        label: 'gbuffer pipeline',
        layout: 'auto',
        vertex: {
            module: gBufferShaderModule,
            entryPoint: "vs",
            buffers: [
                {
                    arrayStride: 12,
                    attributes: [{
                        shaderLocation: 0,
                        format: "float32x3",
                        offset: 0
                    }]
                },
                {
                    arrayStride: 12,
                    attributes: [{
                        shaderLocation: 1,
                        format: "float32x3",
                        offset: 0
                    }]
                },
                {
                    arrayStride: 8,
                    attributes: [{
                        shaderLocation: 2,
                        format: "float32x2",
                        offset: 0
                    }]
                }
            ]
        },
        fragment: {
            module: gBufferShaderModule,
            entryPoint: "fs",

            targets: [
                {
                    format: "rgba16float"
                },
                {
                    format: "rgba16float"
                },
                {
                    format: "rg16float"
                }
            ]
        },
        multisample: {
            count: 4
        },
        primitive: {
            topology: "triangle-list",
            cullMode: "back"
        },
        depthStencil: {
            format: "depth24plus",
            depthWriteEnabled: true,
            depthCompare: "less"
        }
    });

    // Objects
    const boxes = new Array(NUM_BOXES).fill(null).map(() => {
        const translate = [
            randomRange(-3, 3),
            randomRange(-3, 3),
            randomRange(-4, 0)
        ];
        const rotate = [
                randomRange(0, 2 * Math.PI),
                randomRange(0, 2 * Math.PI),
                randomRange(0, 2 * Math.PI) 
        ];
        const scale = [
            0.25,
            0.25,
            0.25
        ];

        const uniformBuffer = device.createBuffer({
            size: 64,
            usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
        });
       
        const bindGroup = device.createBindGroup({
            layout: gBufferPipeline.getBindGroupLayout(0),
            entries: [
                {
                    binding: 0,
                    resource: {
                        buffer: viewProjectionMatrixBuffer
                    }
                },
                {
                    binding: 1,
                    resource: {
                        buffer: uniformBuffer
                    }
                }
            ]
        });

        return {
            translate,
            rotate,
            scale,
            modelMatrix: mat4.create(),
            uniformBuffer,
            bindGroup
        };
    });

    /////////////////////////////////////////
    // Lighting pass
    // (Render a full-screen quad and apply
    //  lighting to data in gBuffer)
    /////////////////////////////////////////

    // Uniforms
    const lightingEyePositionBuffer = device.createBuffer({
        size: 16,
        usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
    });

    device.queue.writeBuffer(lightingEyePositionBuffer, 0, eyePosition);

    // Shader module
    const lightingShaderModule = device.createShaderModule({
        code: `

            @vertex
            fn vs(@location(0) position: vec4f) -> @builtin(position) vec4f {
                return position;
            }

            const lightDampening = 0.06;

            @group(0) @binding(0) var<uniform>  eyePosition: vec4f;
            @group(0) @binding(1) var<uniform> lightPositions: array<vec4f, ${NUM_LIGHTS}>;
            @group(0) @binding(2) var<uniform> lightColors: array<vec4f, ${NUM_LIGHTS}>;
            @group(0) @binding(3) var textureSampler: sampler;
            @group(0) @binding(4) var positionTexture: texture_multisampled_2d<f32>;
            @group(0) @binding(5) var normalTexture: texture_multisampled_2d<f32>;
            @group(0) @binding(6) var uvTexture: texture_multisampled_2d<f32>;
            @group(0) @binding(7) var colorTexture: texture_2d<f32>;

            @fragment
            fn fs(
                @builtin(position) canvasPosition: vec4f, 
                @builtin(sample_index) sampleIndex: u32
            ) -> @location(0) vec4f {
                let index = vec2u(canvasPosition.xy);
                let positionSample = textureLoad(positionTexture, index, sampleIndex);
                let normal = normalize(textureLoad(normalTexture, index, sampleIndex).xyz);
                let uv = textureLoad(uvTexture, index, sampleIndex).xy;

                let surfaceColor: vec3f = textureSample(colorTexture, textureSampler, uv).rgb;

                if (positionSample.w == 0.0) {
                    discard;
                }

                let position = positionSample.xyz;

                let eyeDirection: vec3f = normalize(eyePosition.xyz - position);
                var color = vec3f(0.0);

                for (var i = 0; i < ${NUM_LIGHTS}; i++) {
                    let lightPosition = lightPositions[i].xyz;
                    let lightColor = lightColors[i].rgb * lightDampening;
                    let lightVec: vec3f = lightPosition - position;
                    let lightDirection = normalize(lightVec);
                    let reflectionDirection = reflect(-lightDirection, normal);
                    let nDotL: f32 = max(dot(lightDirection, normal), 0.0);
                    let diffuse: vec3f = nDotL * lightColor;
                    let specular: vec3f = pow(max(dot(reflectionDirection, eyeDirection), 0.0), 20.0) * lightColor;
                    let lightDistance: f32 = length(lightVec);
                    let attenuation: f32 = 1.0 / (lightDistance * lightDistance);
                    color += attenuation * surfaceColor * (diffuse + specular);
                }

                return vec4f(color, 1.0);
            }

        `
    });

    // Pipeline
    const lightingPipeline = device.createRenderPipeline({
        label: 'lighting pipeline',
        layout: 'auto',
        vertex: {
            module: lightingShaderModule,
            entryPoint: "vs",
            buffers: [
                {
                    arrayStride: 8,
                    attributes: [{
                        shaderLocation: 0,
                        format: "float32x2",
                        offset: 0
                    }]
                },
            ]
        },
        fragment: {
            module: lightingShaderModule,
            entryPoint: "fs",
            targets: [{
                format: presentationFormat,
            }],
        },
        multisample: {
            count: 4
        },
        primitive: {
            topology: "triangle-strip",
            cullMode: "back"
        }
    });

    // Bind group
    const lightingBindGroup = device.createBindGroup({
        layout: lightingPipeline.getBindGroupLayout(0),
        entries: [
            {
                binding: 0,
                resource: {
                    buffer: lightingEyePositionBuffer
                }
            },
            {
                binding: 1,
                resource: {
                    buffer: lights.positions
                }
            },
            {
                binding: 2,
                resource: {
                    buffer: lights.colors
                }
            },
            {
                binding: 3,
                resource: sampler
            },
            {
                binding: 4,
                resource: gBufferPositionsTexture.createView()
            },
            {
                binding: 5,
                resource: gBufferNormalsTexture.createView()
            },
            {
                binding: 6,
                resource: gBufferUVTexture.createView()
            },
            {
                binding: 7,
                resource: colorTexture.createView()
            }
        ]
    });


    //////////////////////////////
    // Render pass descriptions
    //////////////////////////////
    
    const depthTexture = device.createTexture({
        label: 'depth texture',
        size: [canvas.width, canvas.height],
        format: "depth24plus",
        usage:  GPUTextureUsage.RENDER_ATTACHMENT,
        sampleCount: 4
    });

    const lightsRenderPassDescription = {
        label: 'lights render pass',
        colorAttachments: [
            {
                view: msaaTexture.createView(),
                resolveTarget: context.getCurrentTexture().createView(),
                loadOp: "clear",
                storeOp: "store",
                clearValue: [0, 0, 0, 1]
            }
        ],
        depthStencilAttachment: {
            view: depthTexture.createView(),
            depthClearValue: 1,
            depthLoadOp: "clear",
            depthStoreOp: "store"
        }
    };

    const gBufferRenderPassDescription = {
        label: 'gbuffer render pass',
        colorAttachments: [
            {
                view: gBufferPositionsTexture.createView(),
                loadOp: "clear",
                storeOp: "store",
                clearValue: [0, 0, 0, 0]
            },
            {
                view: gBufferNormalsTexture.createView(),
                loadOp: "clear",
                storeOp: "store",
                clearValue: [0, 0, 0, 0]
            },
            {
                view: gBufferUVTexture.createView(),
                loadOp: "clear",
                storeOp: "store",
                clearValue: [0, 0, 0, 0]
            }
        ],
        depthStencilAttachment: {
            view: depthTexture.createView(),
            depthLoadOp: "load",
            depthStoreOp: "store"
        }
    };


    const lightingRenderPassDescription = {
        label: 'lighting render pass',
        colorAttachments: [{
            view: msaaTexture.createView(),
            resolveTarget: context.getCurrentTexture().createView(),
            loadOp: "load",
            storeOp: "store",
        }]
    };

    function draw() {
        ///////////////////////////
        // Update box positions
        ///////////////////////////

        for (const box of boxes) {
            box.rotate[0] += 0.0005;
            box.rotate[1] += 0.001;

            xformMatrix(box.modelMatrix, box.translate, box.rotate, box.scale);
            
            device.queue.writeBuffer(box.uniformBuffer, 0, box.modelMatrix);
        }


        ///////////////////////////
        // Update light positions
        ///////////////////////////

        lights.data.forEach((light, i) => {
            light.t = (light.t + 0.002) % (2 * Math.PI);
            const position = lights.positionData.subarray(i * 4, i * 4 + 3);
            vec3.scale(position, light.offset, Math.sin(light.t));
            vec3.add(position, light.position, position);
        });

        device.queue.writeBuffer(lights.positions, 0, lights.positionData);


        /////////////////////////////////////
        // Create command encoder
        /////////////////////////////////////

        const commandEncoder = device.createCommandEncoder();

        /////////////////////////////////////
        // Draw lights as spheres to canvas
        /////////////////////////////////////

        lightsRenderPassDescription.colorAttachments[0].resolveTarget = context.getCurrentTexture().createView();

        const lightsRenderPass = commandEncoder.beginRenderPass(lightsRenderPassDescription);
        lightsRenderPass.setPipeline(lightsPipeline);
        lightsRenderPass.setVertexBuffer(0, sphere.positions);
        lightsRenderPass.setVertexBuffer(1, lights.positions);
        lightsRenderPass.setVertexBuffer(2, lights.colors);
        lightsRenderPass.setIndexBuffer(sphere.indices, "uint32");
        lightsRenderPass.setBindGroup(0, lights.bindGroup);
        lightsRenderPass.drawIndexed(sphere.count, NUM_LIGHTS);           
        lightsRenderPass.end();

        //////////////////////////////////////////////
        // Draw boxes to GBuffer
        // (Depth buffer shared with previous pass)
        //////////////////////////////////////////////

        const gBufferPass = commandEncoder.beginRenderPass(gBufferRenderPassDescription);
        gBufferPass.setPipeline(gBufferPipeline);
        gBufferPass.setVertexBuffer(0, cube.positions);
        gBufferPass.setVertexBuffer(1, cube.normals);
        gBufferPass.setVertexBuffer(2, cube.uvs);

        for (const box of boxes) {
            gBufferPass.setBindGroup(0, box.bindGroup);
            gBufferPass.draw(cube.count);           
        }

        gBufferPass.end();

        //////////////////////////////////
        // Draw a full-screen quad and
        // apply lighting to data in
        // GBuffer.
        //////////////////////////////////

        lightingRenderPassDescription.colorAttachments[0].resolveTarget = context.getCurrentTexture().createView();

        const lightingRenderPass = commandEncoder.beginRenderPass(lightingRenderPassDescription);

        lightingRenderPass.setPipeline(lightingPipeline);
        lightingRenderPass.setVertexBuffer(0, quad.positions);
        lightingRenderPass.setBindGroup(0, lightingBindGroup);
        lightingRenderPass.draw(quad.count);           
        lightingRenderPass.end();

        /////////////////////////////////////
        // Close command encoder and submit
        /////////////////////////////////////
        device.queue.submit([commandEncoder.finish()]);

        requestAnimationFrame(draw);
    }

    requestAnimationFrame(draw);


})();
</script>
</body>
</html>
